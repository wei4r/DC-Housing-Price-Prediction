{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59319e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSL                    0\n",
      "BATHRM                 0\n",
      "HF_BATHRM              0\n",
      "HEAT                   0\n",
      "HEAT_D                 0\n",
      "AC                    20\n",
      "NUM_UNITS              0\n",
      "ROOMS                  0\n",
      "BEDRM                  0\n",
      "AYB                   11\n",
      "EYB                    0\n",
      "STORIES              120\n",
      "SALEDATE               0\n",
      "PRICE                  0\n",
      "QUALIFIED              0\n",
      "SALE_NUM               0\n",
      "GBA                    0\n",
      "BLDG_NUM               0\n",
      "STYLE                  0\n",
      "STYLE_D                0\n",
      "STRUCT                 0\n",
      "STRUCT_D               0\n",
      "GRADE                  0\n",
      "GRADE_D                0\n",
      "CNDTN                  0\n",
      "CNDTN_D                0\n",
      "EXTWALL                0\n",
      "EXTWALL_D              0\n",
      "ROOF                   0\n",
      "ROOF_D                 0\n",
      "INTWALL                0\n",
      "INTWALL_D              0\n",
      "KITCHENS               0\n",
      "FIREPLACES             0\n",
      "USECODE                0\n",
      "LANDAREA               0\n",
      "GIS_LAST_MOD_DTTM      0\n",
      "OBJECTID               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (you can adjust the file path)\n",
    "file_path = 'Computer_Assisted_Mass_Appraisal_-_Residential.csv'\n",
    "dataset = pd.read_csv(file_path)\n",
    "\n",
    "# Drop columns with high percentage of missing values (like 'YR_RMDL')\n",
    "dataset_cleaned = dataset.drop(columns=['YR_RMDL'])\n",
    "dataset_cleaned = dataset_cleaned.dropna(subset=['PRICE'])\n",
    "dataset_cleaned = dataset_cleaned[(dataset_cleaned['GBA'] > 0) & (dataset_cleaned['GBA'].notna()) & (dataset_cleaned['AC'].notna()) & (dataset_cleaned['PRICE'] > 0)]\n",
    "\n",
    "# Encode AC Y/N to 1 and 0\n",
    "dataset_cleaned['AC'] = dataset_cleaned['AC'].map({'Y': True, 'N': False})\n",
    "\n",
    "# Drop rows with missing values in 'ROOMS', 'BEDRM', 'KITCHENS', and 'FIREPLACES'\n",
    "columns_to_check = ['ROOMS', 'BEDRM', 'KITCHENS', 'FIREPLACES', 'AC', 'AYB', 'STORIES']\n",
    "dataset_cleaned = dataset_cleaned.dropna(subset=columns_to_check)\n",
    "\n",
    "# For categorical columns, fill missing values with the mode (e.g., for 'STYLE', 'GRADE', etc.)\n",
    "dataset_cleaned['STYLE'].fillna(dataset_cleaned['STYLE'].mode()[0], inplace=True)\n",
    "dataset_cleaned['GRADE'].fillna(dataset_cleaned['GRADE'].mode()[0], inplace=True)\n",
    "dataset_cleaned['STRUCT'].fillna(dataset_cleaned['STRUCT'].mode()[0], inplace=True)\n",
    "\n",
    "# You can continue this process for other columns as needed\n",
    "\n",
    "# Save the cleaned dataset if needed\n",
    "# dataset_cleaned.to_csv('cleaned_dataset.csv', index=False)\n",
    "\n",
    "# Check if there are any remaining missing values\n",
    "print(dataset_cleaned.isnull().sum())\n",
    "data = dataset_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f46b0b3",
   "metadata": {},
   "source": [
    "### Drop unnessary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2fe3edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BATHRM</th>\n",
       "      <th>HF_BATHRM</th>\n",
       "      <th>HEAT</th>\n",
       "      <th>AC</th>\n",
       "      <th>NUM_UNITS</th>\n",
       "      <th>ROOMS</th>\n",
       "      <th>BEDRM</th>\n",
       "      <th>AYB</th>\n",
       "      <th>EYB</th>\n",
       "      <th>STORIES</th>\n",
       "      <th>...</th>\n",
       "      <th>STRUCT</th>\n",
       "      <th>GRADE</th>\n",
       "      <th>CNDTN</th>\n",
       "      <th>EXTWALL</th>\n",
       "      <th>ROOF</th>\n",
       "      <th>INTWALL</th>\n",
       "      <th>KITCHENS</th>\n",
       "      <th>FIREPLACES</th>\n",
       "      <th>USECODE</th>\n",
       "      <th>LANDAREA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1911.0</td>\n",
       "      <td>1989</td>\n",
       "      <td>3.75</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1912.0</td>\n",
       "      <td>1978</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24</td>\n",
       "      <td>936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>1993</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24</td>\n",
       "      <td>936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1912.0</td>\n",
       "      <td>1978</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24</td>\n",
       "      <td>988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1912.0</td>\n",
       "      <td>1993</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24</td>\n",
       "      <td>1674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BATHRM  HF_BATHRM  HEAT    AC  NUM_UNITS  ROOMS  BEDRM     AYB   EYB  \\\n",
       "0     4.0        1.0   8.0  True        1.0   12.0    6.0  1911.0  1989   \n",
       "1     3.0        1.0   1.0  True        2.0   13.0    5.0  1912.0  1978   \n",
       "2     3.0        1.0   7.0  True        2.0    6.0    4.0  1910.0  1993   \n",
       "3     3.0        1.0   7.0  True        2.0   11.0    4.0  1912.0  1978   \n",
       "4     4.0        1.0   1.0  True        3.0   11.0    5.0  1912.0  1993   \n",
       "\n",
       "   STORIES  ... STRUCT  GRADE CNDTN  EXTWALL  ROOF  INTWALL  KITCHENS  \\\n",
       "0     3.75  ...    6.0    8.0   4.0     20.0  11.0      6.0       1.0   \n",
       "1     3.00  ...    6.0    6.0   4.0     14.0   2.0      6.0       2.0   \n",
       "2     3.00  ...    7.0    6.0   4.0     14.0   6.0      6.0       2.0   \n",
       "3     3.00  ...    6.0    6.0   4.0     14.0   6.0      6.0       2.0   \n",
       "4     3.00  ...    7.0    6.0   5.0     14.0   2.0      6.0       3.0   \n",
       "\n",
       "   FIREPLACES  USECODE  LANDAREA  \n",
       "0         6.0       11      2104  \n",
       "1         3.0       24       936  \n",
       "2         2.0       24       936  \n",
       "3         2.0       24       988  \n",
       "4         4.0       24      1674  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns=['SSL', 'BLDG_NUM', 'SALE_NUM', 'HEAT_D', 'STYLE_D', 'STRUCT_D', 'GRADE_D', 'CNDTN_D', 'EXTWALL_D', 'ROOF_D', 'INTWALL_D', 'GIS_LAST_MOD_DTTM', 'OBJECTID'], inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243f2808",
   "metadata": {},
   "source": [
    "### Modify date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "608a9196",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SALEDATE'] = pd.to_datetime(data['SALEDATE'])\n",
    "\n",
    "# Remove the time part, keeping only the date (this will keep Year, Month, Day)\n",
    "data['SALEDATE'] = data['SALEDATE'].dt.date\n",
    "\n",
    "# Optionally, you can extract specific components from the date for model training\n",
    "data['SALE_YEAR'] = pd.DatetimeIndex(data['SALEDATE']).year\n",
    "data['SALE_MONTH'] = pd.DatetimeIndex(data['SALEDATE']).month\n",
    "\n",
    "# Drop the original 'SALEDATE' column if not needed\n",
    "data = data.drop(columns=['SALEDATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49b34649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 62320 entries, 0 to 109033\n",
      "Data columns (total 26 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   BATHRM      62320 non-null  float64\n",
      " 1   HF_BATHRM   62320 non-null  float64\n",
      " 2   HEAT        62320 non-null  float64\n",
      " 3   AC          62299 non-null  object \n",
      " 4   NUM_UNITS   62320 non-null  float64\n",
      " 5   ROOMS       62320 non-null  float64\n",
      " 6   BEDRM       62320 non-null  float64\n",
      " 7   AYB         62309 non-null  float64\n",
      " 8   EYB         62320 non-null  int64  \n",
      " 9   STORIES     62192 non-null  float64\n",
      " 10  PRICE       62320 non-null  float64\n",
      " 11  QUALIFIED   62320 non-null  object \n",
      " 12  GBA         62320 non-null  int64  \n",
      " 13  STYLE       62320 non-null  float64\n",
      " 14  STRUCT      62320 non-null  float64\n",
      " 15  GRADE       62320 non-null  float64\n",
      " 16  CNDTN       62320 non-null  float64\n",
      " 17  EXTWALL     62320 non-null  float64\n",
      " 18  ROOF        62320 non-null  float64\n",
      " 19  INTWALL     62320 non-null  float64\n",
      " 20  KITCHENS    62320 non-null  float64\n",
      " 21  FIREPLACES  62320 non-null  float64\n",
      " 22  USECODE     62320 non-null  int64  \n",
      " 23  LANDAREA    62320 non-null  int64  \n",
      " 24  SALE_YEAR   62320 non-null  int32  \n",
      " 25  SALE_MONTH  62320 non-null  int32  \n",
      "dtypes: float64(18), int32(2), int64(4), object(2)\n",
      "memory usage: 12.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BATHRM</th>\n",
       "      <th>HF_BATHRM</th>\n",
       "      <th>HEAT</th>\n",
       "      <th>AC</th>\n",
       "      <th>NUM_UNITS</th>\n",
       "      <th>ROOMS</th>\n",
       "      <th>BEDRM</th>\n",
       "      <th>AYB</th>\n",
       "      <th>EYB</th>\n",
       "      <th>STORIES</th>\n",
       "      <th>...</th>\n",
       "      <th>CNDTN</th>\n",
       "      <th>EXTWALL</th>\n",
       "      <th>ROOF</th>\n",
       "      <th>INTWALL</th>\n",
       "      <th>KITCHENS</th>\n",
       "      <th>FIREPLACES</th>\n",
       "      <th>USECODE</th>\n",
       "      <th>LANDAREA</th>\n",
       "      <th>SALE_YEAR</th>\n",
       "      <th>SALE_MONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1911.0</td>\n",
       "      <td>1989</td>\n",
       "      <td>3.75</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2104</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1912.0</td>\n",
       "      <td>1978</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24</td>\n",
       "      <td>936</td>\n",
       "      <td>1999</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>1993</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24</td>\n",
       "      <td>936</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1912.0</td>\n",
       "      <td>1978</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24</td>\n",
       "      <td>988</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1912.0</td>\n",
       "      <td>1993</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24</td>\n",
       "      <td>1674</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BATHRM  HF_BATHRM  HEAT    AC  NUM_UNITS  ROOMS  BEDRM     AYB   EYB  \\\n",
       "0     4.0        1.0   8.0  True        1.0   12.0    6.0  1911.0  1989   \n",
       "1     3.0        1.0   1.0  True        2.0   13.0    5.0  1912.0  1978   \n",
       "2     3.0        1.0   7.0  True        2.0    6.0    4.0  1910.0  1993   \n",
       "3     3.0        1.0   7.0  True        2.0   11.0    4.0  1912.0  1978   \n",
       "4     4.0        1.0   1.0  True        3.0   11.0    5.0  1912.0  1993   \n",
       "\n",
       "   STORIES  ...  CNDTN EXTWALL  ROOF  INTWALL  KITCHENS  FIREPLACES  USECODE  \\\n",
       "0     3.75  ...    4.0    20.0  11.0      6.0       1.0         6.0       11   \n",
       "1     3.00  ...    4.0    14.0   2.0      6.0       2.0         3.0       24   \n",
       "2     3.00  ...    4.0    14.0   6.0      6.0       2.0         2.0       24   \n",
       "3     3.00  ...    4.0    14.0   6.0      6.0       2.0         2.0       24   \n",
       "4     3.00  ...    5.0    14.0   2.0      6.0       3.0         4.0       24   \n",
       "\n",
       "   LANDAREA  SALE_YEAR  SALE_MONTH  \n",
       "0      2104       2019           8  \n",
       "1       936       1999           8  \n",
       "2       936       2019           7  \n",
       "3       988       2021          10  \n",
       "4      1674       2023           4  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5789dd49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BATHRM', 'HF_BATHRM', 'HEAT', 'AC', 'NUM_UNITS', 'ROOMS', 'BEDRM',\n",
       "       'AYB', 'EYB', 'STORIES', 'PRICE', 'QUALIFIED', 'GBA', 'STYLE', 'STRUCT',\n",
       "       'GRADE', 'CNDTN', 'EXTWALL', 'ROOF', 'INTWALL', 'KITCHENS',\n",
       "       'FIREPLACES', 'USECODE', 'LANDAREA', 'SALE_YEAR', 'SALE_MONTH'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed4f830",
   "metadata": {},
   "source": [
    "### Feature Selection and Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60e77a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Feature Selection\n",
    "numerical_features = ['BATHRM', 'HF_BATHRM', 'ROOMS', 'BEDRM', 'AYB', 'EYB', 'STORIES', 'GBA', 'KITCHENS', 'FIREPLACES', 'LANDAREA', 'SALE_YEAR', 'SALE_MONTH']\n",
    "categorical_features = ['HEAT', 'AC', 'STYLE', 'STRUCT', 'GRADE', 'CNDTN', 'EXTWALL', 'ROOF', 'INTWALL', 'USECODE']\n",
    "\n",
    "# Feature Engineering\n",
    "data['AGE'] = data['SALE_YEAR'] - data['AYB']\n",
    "data['TOTAL_ROOMS'] = data['ROOMS'] + data['BATHRM'] + data['HF_BATHRM']\n",
    "data['PRICE_PER_SQFT'] = data['PRICE'] / data['GBA']\n",
    "\n",
    "# Log transform of the target variable (often helps with price predictions)\n",
    "data['LOG_PRICE'] = np.log(data['PRICE'])\n",
    "\n",
    "# Update features list\n",
    "numerical_features += ['AGE', 'TOTAL_ROOMS', 'PRICE_PER_SQFT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b217b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         484.109387\n",
       "1         241.016652\n",
       "2         843.253968\n",
       "3         737.463127\n",
       "4         840.866290\n",
       "             ...    \n",
       "109026    355.713651\n",
       "109028    170.000000\n",
       "109030    290.949336\n",
       "109031    247.579530\n",
       "109033    577.888134\n",
       "Name: PRICE_PER_SQFT, Length: 62320, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['PRICE_PER_SQFT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fc78fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('processed_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3342e3e0",
   "metadata": {},
   "source": [
    "### Categorical Variable Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8675b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'OneHotEncoder' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLOG_PRICE\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Using log-transformed price\u001b[39;00m\n\u001b[1;32m     11\u001b[0m X_encoded \u001b[38;5;241m=\u001b[39m ct\u001b[38;5;241m.\u001b[39mfit_transform(X)\n\u001b[1;32m     12\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m (ct\u001b[38;5;241m.\u001b[39mnamed_transformers_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124monehot\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 13\u001b[0m                     \u001b[38;5;241m.\u001b[39mget_feature_names(categorical_features)\n\u001b[1;32m     14\u001b[0m                     \u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;241m+\u001b[39m numerical_features)\n\u001b[1;32m     15\u001b[0m X_encoded \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_encoded, columns\u001b[38;5;241m=\u001b[39mfeature_names)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'OneHotEncoder' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "onehot = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "ct = ColumnTransformer([(\"onehot\", onehot, categorical_features)], remainder='passthrough')\n",
    "   \n",
    "X = data[numerical_features + categorical_features]\n",
    "y = data['LOG_PRICE']  # Using log-transformed price\n",
    "\n",
    "X_encoded = ct.fit_transform(X)\n",
    "feature_names = (ct.named_transformers_['onehot']\n",
    "                    .get_feature_names(categorical_features)\n",
    "                    .tolist() + numerical_features)\n",
    "X_encoded = pd.DataFrame(X_encoded, columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a2ab97",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8f72952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with infinite values: ['PRICE_PER_SQFT']\n",
      "Columns with very large values: ['PRICE_PER_SQFT']\n",
      "\n",
      "Statistics for PRICE_PER_SQFT:\n",
      "count    9.613400e+04\n",
      "mean              inf\n",
      "std               NaN\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      2.185000e+02\n",
      "75%      4.779412e+02\n",
      "max               inf\n",
      "Name: PRICE_PER_SQFT, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check for infinite values\n",
    "inf_columns = X_encoded.columns[np.isinf(X_encoded).any()].tolist()\n",
    "print(\"Columns with infinite values:\", inf_columns)\n",
    "\n",
    "# Check for very large values\n",
    "large_columns = X_encoded.columns[(np.abs(X_encoded) > 1e300).any()].tolist()\n",
    "print(\"Columns with very large values:\", large_columns)\n",
    "\n",
    "# Display some statistics for these columns\n",
    "if inf_columns or large_columns:\n",
    "    problem_columns = set(inf_columns + large_columns)\n",
    "    for col in problem_columns:\n",
    "        print(f\"\\nStatistics for {col}:\")\n",
    "        print(X_encoded[col].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "393683d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with infinite values after handling: []\n",
      "Columns with very large values after handling: []\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Replace infinite values with NaN and then with a large number\n",
    "X_encoded = X_encoded.replace([np.inf, -np.inf], np.nan)\n",
    "X_encoded = X_encoded.fillna(X_encoded.max() * 2)  # or another suitable large value\n",
    "\n",
    "# Method 2: Clip values to a reasonable range\n",
    "# X_encoded = X_encoded.clip(lower=-1e300, upper=1e300)\n",
    "\n",
    "# Method 3: Remove rows with problematic values (use cautiously as it may remove a lot of data)\n",
    "# X_encoded = X_encoded.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# After handling, check again for any remaining issues\n",
    "print(\"Columns with infinite values after handling:\", X_encoded.columns[np.isinf(X_encoded).any()].tolist())\n",
    "print(\"Columns with very large values after handling:\", X_encoded.columns[(np.abs(X_encoded) > 1e300).any()].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89f7375e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardization completed successfully.\n",
      "           HEAT_0.0      HEAT_1.0      HEAT_2.0      HEAT_3.0      HEAT_4.0  \\\n",
      "count  9.682700e+04  9.682700e+04  9.682700e+04  9.682700e+04  9.682700e+04   \n",
      "mean  -2.917762e-15 -2.853788e-14 -7.660121e-15 -2.532476e-15  2.900936e-15   \n",
      "std    1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00   \n",
      "min   -1.901579e-02 -7.560838e-01 -2.631416e-02 -4.081089e-02 -2.551605e-02   \n",
      "25%   -1.901579e-02 -7.560838e-01 -2.631416e-02 -4.081089e-02 -2.551605e-02   \n",
      "50%   -1.901579e-02 -7.560838e-01 -2.631416e-02 -4.081089e-02 -2.551605e-02   \n",
      "75%   -1.901579e-02  1.322605e+00 -2.631416e-02 -4.081089e-02 -2.551605e-02   \n",
      "max    5.258789e+01  1.322605e+00  3.800236e+01  2.450326e+01  3.919103e+01   \n",
      "\n",
      "           HEAT_5.0      HEAT_6.0      HEAT_7.0      HEAT_8.0      HEAT_9.0  \\\n",
      "count  9.682700e+04  9.682700e+04  9.682700e+04  9.682700e+04  9.682700e+04   \n",
      "mean  -8.822975e-16 -2.523788e-15 -4.037938e-14 -4.417981e-14  3.553850e-15   \n",
      "std    1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00   \n",
      "min   -3.418177e-02 -4.004198e-02 -5.663342e-01 -1.432503e-01 -1.638878e-02   \n",
      "25%   -3.418177e-02 -4.004198e-02 -5.663342e-01 -1.432503e-01 -1.638878e-02   \n",
      "50%   -3.418177e-02 -4.004198e-02 -5.663342e-01 -1.432503e-01 -1.638878e-02   \n",
      "75%   -3.418177e-02 -4.004198e-02 -5.663342e-01 -1.432503e-01 -1.638878e-02   \n",
      "max    2.925536e+01  2.497379e+01  1.765742e+00  6.980787e+00  6.101734e+01   \n",
      "\n",
      "       ...       STORIES           GBA      KITCHENS    FIREPLACES  \\\n",
      "count  ...  9.682700e+04  9.682700e+04  9.682700e+04  9.682700e+04   \n",
      "mean   ... -1.005007e-14 -1.842422e-15  1.185145e-14  9.603527e-14   \n",
      "std    ...  1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00   \n",
      "min    ... -3.205182e-01 -1.934609e+00 -2.024918e+00 -6.912898e-01   \n",
      "25%    ... -1.519947e-01 -5.860503e-01 -3.898432e-01 -6.912898e-01   \n",
      "50%    ... -1.519947e-01 -2.399202e-01 -3.898432e-01 -6.912898e-01   \n",
      "75%    ... -1.519947e-01  3.264745e-01 -3.898432e-01  4.150641e-01   \n",
      "max    ...  6.925992e+00  2.507028e+01  1.923106e+01  1.369131e+01   \n",
      "\n",
      "           LANDAREA     SALE_YEAR    SALE_MONTH           AGE   TOTAL_ROOMS  \\\n",
      "count  9.682700e+04  9.682700e+04  9.682700e+04  9.682700e+04  9.682700e+04   \n",
      "mean  -6.229550e-16  3.752537e-15 -1.387892e-15  1.055822e-14 -1.457758e-15   \n",
      "std    1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00   \n",
      "min   -6.345436e-01 -4.632171e+00 -1.558777e+00 -1.909091e+00 -8.180380e-01   \n",
      "25%   -3.389696e-01 -1.339565e-01 -9.790674e-01 -1.524391e-01 -2.915380e-01   \n",
      "50%   -1.938872e-01  2.904034e-01 -1.095034e-01  4.696470e-02 -1.599131e-01   \n",
      "75%    1.515286e-01  5.025834e-01  7.600606e-01  2.083868e-01 -2.828808e-02   \n",
      "max    1.814684e+02  6.298914e-01  1.629625e+00  3.771529e+01  7.079461e+00   \n",
      "\n",
      "       PRICE_PER_SQFT  \n",
      "count    9.682700e+04  \n",
      "mean     7.894887e-15  \n",
      "std      1.000005e+00  \n",
      "min     -1.769384e-01  \n",
      "25%     -1.769384e-01  \n",
      "50%     -1.453494e-01  \n",
      "75%     -1.080579e-01  \n",
      "max      7.239260e+00  \n",
      "\n",
      "[8 rows x 150 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_encoded)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X_encoded.columns)\n",
    "\n",
    "print(\"Standardization completed successfully.\")\n",
    "print(X_scaled.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5ae8229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current statistics for PRICE_PER_SQFT:\n",
      "count    96827.000000\n",
      "mean      1244.313753\n",
      "std       7032.506619\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%        222.148148\n",
      "75%        484.400067\n",
      "max      52154.195011\n",
      "Name: PRICE_PER_SQFT, dtype: float64\n",
      "\n",
      "Recalculated statistics for PRICE_PER_SQFT:\n",
      "count    86605.000000\n",
      "mean       287.148722\n",
      "std        345.125259\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%        219.594595\n",
      "75%        491.129032\n",
      "max      26077.097506\n",
      "Name: PRICE_PER_SQFT, dtype: float64\n",
      "\n",
      "Number of infinite values in PRICE_PER_SQFT: 0\n",
      "Number of very large values (>1e300) in PRICE_PER_SQFT: 0\n"
     ]
    }
   ],
   "source": [
    "# First, let's check if 'PRICE_PER_SQFT' is in X_encoded\n",
    "if 'PRICE_PER_SQFT' in X_encoded.columns:\n",
    "    print(\"Current statistics for PRICE_PER_SQFT:\")\n",
    "    print(X_encoded['PRICE_PER_SQFT'].describe())\n",
    "    \n",
    "    # Remove the current 'PRICE_PER_SQFT' column\n",
    "    X_encoded = X_encoded.drop('PRICE_PER_SQFT', axis=1)\n",
    "\n",
    "# Now, let's recalculate PRICE_PER_SQFT using the original data DataFrame\n",
    "if 'PRICE' in data.columns and 'GBA' in data.columns:\n",
    "    data['PRICE_PER_SQFT'] = data['PRICE'] / data['GBA'].replace(0, np.nan)\n",
    "    data['PRICE_PER_SQFT'] = data['PRICE_PER_SQFT'].fillna(data['PRICE_PER_SQFT'].median())\n",
    "    \n",
    "    # Add the recalculated PRICE_PER_SQFT to X_encoded\n",
    "    X_encoded['PRICE_PER_SQFT'] = data['PRICE_PER_SQFT']\n",
    "    \n",
    "    print(\"\\nRecalculated statistics for PRICE_PER_SQFT:\")\n",
    "    print(X_encoded['PRICE_PER_SQFT'].describe())\n",
    "else:\n",
    "    print(\"Error: 'PRICE' or 'GBA' column not found in the original data DataFrame\")\n",
    "\n",
    "# Check for infinite or very large values\n",
    "inf_check = np.isinf(X_encoded['PRICE_PER_SQFT']).sum()\n",
    "large_check = (np.abs(X_encoded['PRICE_PER_SQFT']) > 1e300).sum()\n",
    "\n",
    "print(f\"\\nNumber of infinite values in PRICE_PER_SQFT: {inf_check}\")\n",
    "print(f\"Number of very large values (>1e300) in PRICE_PER_SQFT: {large_check}\")\n",
    "\n",
    "# If there are still issues, we can apply a cap\n",
    "if inf_check > 0 or large_check > 0:\n",
    "    upper_limit = X_encoded['PRICE_PER_SQFT'].quantile(0.99)  # 99th percentile\n",
    "    X_encoded['PRICE_PER_SQFT'] = X_encoded['PRICE_PER_SQFT'].clip(upper=upper_limit)\n",
    "    \n",
    "    print(\"\\nAfter applying cap:\")\n",
    "    print(X_encoded['PRICE_PER_SQFT'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d6f1889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardization completed successfully.\n",
      "           HEAT_0.0      HEAT_1.0      HEAT_2.0      HEAT_3.0      HEAT_4.0  \\\n",
      "count  9.682700e+04  9.682700e+04  9.682700e+04  9.682700e+04  9.682700e+04   \n",
      "mean  -2.917762e-15 -2.853788e-14 -7.660121e-15 -2.532476e-15  2.900936e-15   \n",
      "std    1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00   \n",
      "min   -1.901579e-02 -7.560838e-01 -2.631416e-02 -4.081089e-02 -2.551605e-02   \n",
      "25%   -1.901579e-02 -7.560838e-01 -2.631416e-02 -4.081089e-02 -2.551605e-02   \n",
      "50%   -1.901579e-02 -7.560838e-01 -2.631416e-02 -4.081089e-02 -2.551605e-02   \n",
      "75%   -1.901579e-02  1.322605e+00 -2.631416e-02 -4.081089e-02 -2.551605e-02   \n",
      "max    5.258789e+01  1.322605e+00  3.800236e+01  2.450326e+01  3.919103e+01   \n",
      "\n",
      "           HEAT_5.0      HEAT_6.0      HEAT_7.0      HEAT_8.0      HEAT_9.0  \\\n",
      "count  9.682700e+04  9.682700e+04  9.682700e+04  9.682700e+04  9.682700e+04   \n",
      "mean  -8.822975e-16 -2.523788e-15 -4.037938e-14 -4.417981e-14  3.553850e-15   \n",
      "std    1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00   \n",
      "min   -3.418177e-02 -4.004198e-02 -5.663342e-01 -1.432503e-01 -1.638878e-02   \n",
      "25%   -3.418177e-02 -4.004198e-02 -5.663342e-01 -1.432503e-01 -1.638878e-02   \n",
      "50%   -3.418177e-02 -4.004198e-02 -5.663342e-01 -1.432503e-01 -1.638878e-02   \n",
      "75%   -3.418177e-02 -4.004198e-02 -5.663342e-01 -1.432503e-01 -1.638878e-02   \n",
      "max    2.925536e+01  2.497379e+01  1.765742e+00  6.980787e+00  6.101734e+01   \n",
      "\n",
      "       ...       STORIES           GBA      KITCHENS    FIREPLACES  \\\n",
      "count  ...  9.682700e+04  9.682700e+04  9.682700e+04  9.682700e+04   \n",
      "mean   ... -1.005007e-14 -1.842422e-15  1.185145e-14  9.603527e-14   \n",
      "std    ...  1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00   \n",
      "min    ... -3.205182e-01 -1.934609e+00 -2.024918e+00 -6.912898e-01   \n",
      "25%    ... -1.519947e-01 -5.860503e-01 -3.898432e-01 -6.912898e-01   \n",
      "50%    ... -1.519947e-01 -2.399202e-01 -3.898432e-01 -6.912898e-01   \n",
      "75%    ... -1.519947e-01  3.264745e-01 -3.898432e-01  4.150641e-01   \n",
      "max    ...  6.925992e+00  2.507028e+01  1.923106e+01  1.369131e+01   \n",
      "\n",
      "           LANDAREA     SALE_YEAR    SALE_MONTH           AGE   TOTAL_ROOMS  \\\n",
      "count  9.682700e+04  9.682700e+04  9.682700e+04  9.682700e+04  9.682700e+04   \n",
      "mean  -6.229550e-16  3.752537e-15 -1.387892e-15  1.055822e-14 -1.457758e-15   \n",
      "std    1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00   \n",
      "min   -6.345436e-01 -4.632171e+00 -1.558777e+00 -1.909091e+00 -8.180380e-01   \n",
      "25%   -3.389696e-01 -1.339565e-01 -9.790674e-01 -1.524391e-01 -2.915380e-01   \n",
      "50%   -1.938872e-01  2.904034e-01 -1.095034e-01  4.696470e-02 -1.599131e-01   \n",
      "75%    1.515286e-01  5.025834e-01  7.600606e-01  2.083868e-01 -2.828808e-02   \n",
      "max    1.814684e+02  6.298914e-01  1.629625e+00  3.771529e+01  7.079461e+00   \n",
      "\n",
      "       PRICE_PER_SQFT  \n",
      "count    8.660500e+04  \n",
      "mean     1.342178e-14  \n",
      "std      1.000006e+00  \n",
      "min     -8.320179e-01  \n",
      "25%     -8.320179e-01  \n",
      "50%     -1.957391e-01  \n",
      "75%      5.910361e-01  \n",
      "max      7.472678e+01  \n",
      "\n",
      "[8 rows x 150 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_encoded)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X_encoded.columns)\n",
    "\n",
    "print(\"Standardization completed successfully.\")\n",
    "print(X_scaled.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddb878a",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55ccd151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (77461, 150)\n",
      "Testing set shape: (19366, 150)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming y is your target variable (house prices)\n",
    "y = data['PRICE']  # Make sure this is the correct column name for your target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a2d850",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f788c9a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/pattysung/DC-Housing-Price-Prediction/Washington, D.C. Housing Price Prediction.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pattysung/DC-Housing-Price-Prediction/Washington%2C%20D.C.%20Housing%20Price%20Prediction.ipynb#X52sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Linear Regression\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pattysung/DC-Housing-Price-Prediction/Washington%2C%20D.C.%20Housing%20Price%20Prediction.ipynb#X52sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m lr_model \u001b[39m=\u001b[39m LinearRegression()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pattysung/DC-Housing-Price-Prediction/Washington%2C%20D.C.%20Housing%20Price%20Prediction.ipynb#X52sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m lr_model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pattysung/DC-Housing-Price-Prediction/Washington%2C%20D.C.%20Housing%20Price%20Prediction.ipynb#X52sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Random Forest\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pattysung/DC-Housing-Price-Prediction/Washington%2C%20D.C.%20Housing%20Price%20Prediction.ipynb#X52sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m rf_model \u001b[39m=\u001b[39m RandomForestRegressor(n_estimators\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:662\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    658\u001b[0m n_jobs_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs\n\u001b[1;32m    660\u001b[0m accept_sparse \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositive \u001b[39melse\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcoo\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 662\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    663\u001b[0m     X, y, accept_sparse\u001b[39m=\u001b[39;49maccept_sparse, y_numeric\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    664\u001b[0m )\n\u001b[1;32m    666\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    667\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    580\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 581\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    582\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:964\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    962\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39my cannot be None\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 964\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m    965\u001b[0m     X,\n\u001b[1;32m    966\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m    967\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m    968\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    969\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m    970\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    971\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m    972\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m    973\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m    974\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m    975\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m    976\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    977\u001b[0m )\n\u001b[1;32m    979\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric)\n\u001b[1;32m    981\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:800\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    795\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    796\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    797\u001b[0m         )\n\u001b[1;32m    799\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 800\u001b[0m         _assert_all_finite(array, allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    802\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    803\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:114\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    108\u001b[0m         allow_nan\n\u001b[1;32m    109\u001b[0m         \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39misinf(X)\u001b[39m.\u001b[39many()\n\u001b[1;32m    110\u001b[0m         \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan\n\u001b[1;32m    111\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misfinite(X)\u001b[39m.\u001b[39mall()\n\u001b[1;32m    112\u001b[0m     ):\n\u001b[1;32m    113\u001b[0m         type_err \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minfinity\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m allow_nan \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mNaN, infinity\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 114\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    115\u001b[0m             msg_err\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    116\u001b[0m                 type_err, msg_dtype \u001b[39mif\u001b[39;00m msg_dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m X\u001b[39m.\u001b[39mdtype\n\u001b[1;32m    117\u001b[0m             )\n\u001b[1;32m    118\u001b[0m         )\n\u001b[1;32m    119\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Models have been trained successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
